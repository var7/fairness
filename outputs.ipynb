{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## sys imports #############\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import datetime\n",
    "############## basic stats imports #############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "############## pytorch imports #############\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## custom imports #############\n",
    "from dataloader import FaceScrubDataset, TripletFaceScrub, SiameseFaceScrub\n",
    "from dataloader import FaceScrubBalancedBatchSampler\n",
    "\n",
    "from networks import *\n",
    "from losses import OnlineTripletLoss\n",
    "from openface.loadOpenFace import prepareOpenFace\n",
    "from utils import save_checkpoint, save_hyperparams, AverageMeter, HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/home/s1791387/facescrub-data/new_data_max/'\n",
    "DATA_PATH = '/home/var/final-fs-data/'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train_full_with_ids.txt')\n",
    "VALID_PATH = os.path.join(DATA_PATH, 'val_full_with_ids.txt')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test_full_with_ids.txt')\n",
    "# WEIGHTS_PATH = '/home/s1791387/facescrub-data/new_data_max/openface_model_weigths/job_semi_std_cos3_Jul_25_1000hrs/weights_75.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "input_size = 96\n",
    "output_dim = 128\n",
    "learning_rate = 1e2\n",
    "num_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "triplet_margin = 1.  # margin\n",
    "triplet_p = 2  # norm degree for distance calculation\n",
    "\n",
    "resume_training = False\n",
    "workers = 8\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set: cuda\n",
      "Training set path: /home/var/final-fs-data/train_full_with_ids.txt\n",
      "Training set Path exists: True\n"
     ]
    }
   ],
   "source": [
    "cuda = False\n",
    "pin_memory = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    cuda = True\n",
    "    cudnn.benchmark = True\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Device set: {}'.format(device))\n",
    "print('Training set path: {}'.format(TRAIN_PATH))\n",
    "print('Training set Path exists: {}'.format(os.path.isfile(TRAIN_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data converted to siamese form. Length: 55731\n",
      "Validation data converted to siamese form. Length: 5970\n",
      "Train loader created. Length of train loader: 109\n",
      "Val loader created. Length of train loader: 12\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "}\n",
    "\n",
    "\n",
    "train_df = FaceScrubDataset(\n",
    "    txt_file=TRAIN_PATH, root_dir=DATA_PATH, transform=data_transforms['val'])\n",
    "\n",
    "val_df = FaceScrubDataset(\n",
    "    txt_file=VALID_PATH, root_dir=DATA_PATH, transform=data_transforms['val'])\n",
    "\n",
    "siamese_train_df = SiameseFaceScrub(train_df, train=True)\n",
    "print('Train data converted to siamese form. Length: {}'.format(len(siamese_train_df)))\n",
    "\n",
    "siamese_val_df=SiameseFaceScrub(val_df, train=False)\n",
    "print('Validation data converted to siamese form. Length: {}'.format(\n",
    "    len(siamese_val_df)))\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(\n",
    "        siamese_train_df, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=workers)\n",
    "print('Train loader created. Length of train loader: {}'.format(\n",
    "        len(train_loader)))\n",
    "    \n",
    "val_loader=torch.utils.data.DataLoader(\n",
    "        siamese_val_df, batch_size=batch_size, shuffle=False, pin_memory=pin_memory, num_workers=workers)\n",
    "print('Val loader created. Length of train loader: {}'.format(\n",
    "        len(val_loader)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent model to GPU\n",
      "Number of params in network 3733968\n"
     ]
    }
   ],
   "source": [
    "openface = prepareOpenFace(useCuda=cuda)\n",
    "params = sum(p.numel() for p in openface.parameters() if p.requires_grad)\n",
    "print('Number of params in network {}'.format(params))\n",
    "\n",
    "en_optimizer=optim.Adam(openface.parameters(), lr=learning_rate)\n",
    "\n",
    "# T_max = num_epochs\n",
    "# eta_min = 0.01\n",
    "# en_scheduler = lr_scheduler.CosineAnnealingLR(en_optimizer, T_max=T_max, eta_min=eta_min)\n",
    "en_scheduler = lr_scheduler.StepLR(en_optimizer, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ClassNet(input_size=output_dim, training=True)\n",
    "cl_optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "T_max = num_epochs\n",
    "eta_min = 0.01\n",
    "# cl_scheduler = lr_scheduler.CosineAnnealingLR(cl_optimizer, T_max=T_max, eta_min=eta_min)\n",
    "cl_scheduler = lr_scheduler.StepLR(cl_optimizer, step_size=1, gamma=0.99)\n",
    "cl_criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    resume_weights=WEIGHTS_PATH\n",
    "    if cuda:\n",
    "        checkpoint=torch.load(resume_weights)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        checkpoint=torch.load(resume_weights,\n",
    "                                map_location=lambda storage,\n",
    "                                loc: storage)\n",
    "\n",
    "    start_epoch=checkpoint['epoch']\n",
    "    openface.load_state_dict(checkpoint['state_dict'])\n",
    "    en_optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    # scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(\n",
    "        resume_weights, checkpoint['epoch']))\n",
    "#     for epoch in range(0, start_epoch):\n",
    "#         en_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent model to gpu True\n"
     ]
    }
   ],
   "source": [
    "if cuda:\n",
    "    openface.cuda()\n",
    "    classifier.cuda()\n",
    "    print('Sent model to gpu {}'.format(\n",
    "        next(openface.parameters()).is_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, classifier, encoder, criterion, en_optimizer, cl_optimizer, epoch, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    print_freq=1\n",
    "    # switch to train mode\n",
    "    classifier.train()\n",
    "    encoder.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, ([imgs1,imgs2], [labels1, labels2], target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        imgs1 = imgs1.to(device)\n",
    "        imgs2 = imgs2.to(device)\n",
    "        target = target.to(device).float()\n",
    "#         print(target.shape, target)\n",
    "        embed1, _ = encoder(imgs1)\n",
    "        embed2, _ = encoder(imgs2)\n",
    "        pair_embed = torch.cat((embed1, embed2), dim=1)\n",
    "#         print(pair_embed.shape)\n",
    "        pred_target = classifier(pair_embed)\n",
    "        pred_target.squeeze_()\n",
    "#         print(pred_target.squeeze_())\n",
    "#         print(pred_target.shape)\n",
    "        loss = cl_criterion(pred_target, target)\n",
    "#         print(loss)\n",
    "        losses.update(loss.item(), imgs1[0].size(0))\n",
    "\n",
    "        en_optimizer.zero_grad()\n",
    "        cl_optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        en_optimizer.step()\n",
    "        cl_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch, batch_idx, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "    return losses.avg\n",
    "\n",
    "def validate(val_loader, classifier, encoder, criterion, epoch, device):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    print_freq=100\n",
    "    # switch to evaluate mode\n",
    "    classifier.eval()\n",
    "    encoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for batch_idx, ([imgs1,imgs2], [labels1, labels2], target) in enumerate(val_loader):\n",
    "            imgs1 = imgs1.to(device)\n",
    "            imgs2 = imgs2.to(device)\n",
    "            target = target.to(device).float()\n",
    "    #         print(target.shape, target)\n",
    "            embed1, _ = openface(imgs1)\n",
    "            embed2, _ = openface(imgs2)\n",
    "            pair_embed = torch.cat((embed1, embed2), dim=1)\n",
    "    #         print(pair_embed.shape)\n",
    "            pred_target = classifier(pair_embed)\n",
    "            pred_target.squeeze_()\n",
    "    #         print(pred_target.squeeze_())\n",
    "    #         print(pred_target.shape)\n",
    "            loss = cl_criterion(pred_target, target)\n",
    "    #         print(loss)\n",
    "            losses.update(loss.item(), imgs1[0].size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                       batch_idx, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Beginning Training\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 5 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2e6e95f336b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopenface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-aba7f6f179ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, classifier, encoder, criterion, en_optimizer, cl_optimizer, epoch, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function takes exactly 5 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "print('-'*10)\n",
    "print('Beginning Training')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epoch_time = AverageMeter()\n",
    "ep_end = time.time()\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "\n",
    "    en_scheduler.step()\n",
    "    cl_scheduler.step()\n",
    "\n",
    "    # train\n",
    "    train_loss = train(train_loader, classifier, openface, cl_criterion, en_optimizer, cl_optimizer, epoch, device)\n",
    "    train_losses.append(train_loss)\n",
    "    # validate\n",
    "    print('-'*10)\n",
    "    val_loss = validate(val_loader, classifier, openface, cl_criterion, epoch, device)\n",
    "\n",
    "    print('Avg validation loss: {}'.format(val_loss))\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': openface.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'best_loss': best_loss\n",
    "        # 'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "    if best_loss > val_loss:\n",
    "        best_loss = val_loss\n",
    "        MODEL_NAME = os.path.join(\n",
    "            WEIGHTS_PATH, 'weights_{}.pth'.format(epoch))\n",
    "        save_checkpoint(state, True, WEIGHTS_PATH, MODEL_NAME)\n",
    "    print('-' * 20)\n",
    "    epoch_time.update(time.time() - ep_end)\n",
    "    ep_end = time.time()\n",
    "    print('Epoch {}/{}\\t'\n",
    "          'Time {epoch_time.val:.3f} sec ({epoch_time.avg:.3f} sec)'.format(epoch, start_epoch + num_epochs - 1, epoch_time=epoch_time))\n",
    "    print('-'*20)\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(embeddings):\n",
    "    import sklearn.manifold\n",
    "    return torch.from_numpy(sklearn.manifold.TSNE(n_iter = 250).fit_transform(embeddings.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svg(points, labels, thumbnails, legend_size = 1e-1, legend_font_size = 5e-2, circle_radius = 5e-3):\n",
    "\tpoints = (points - points.min(0)[0]) / (points.max(0)[0] - points.min(0)[0])\n",
    "\tclass_index = sorted(set(labels))\n",
    "\tclass_colors = [360.0 * i / len(class_index) for i in range(len(class_index))]\n",
    "\tcolors = [class_colors[class_index.index(label)] for label in labels]\n",
    "\tthumbnails_base64 = [base64.b64encode(cv2.imencode('.jpg', img.mul(255).permute(1, 2, 0).numpy()[..., ::-1])[1]) for img in thumbnails]\n",
    "\treturn '<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 1 1\">' + \\\n",
    "\t   ''.join(map('''<circle cx=\"{}\" cy=\"{}\" title=\"{}\" fill=\"hsl({}, 50%, 50%)\" r=\"{}\" desc=\"data:image/jpeg;base64,{}\" onmouseover=\"evt.target.ownerDocument.getElementById('preview').setAttribute('href', evt.target.getAttribute('desc')); evt.target.ownerDocument.getElementById('label').textContent = evt.target.getAttribute('title');\" />'''.format, points[:, 0], points[:, 1], labels, colors, [circle_radius] * len(points), thumbnails_base64)) + \\\n",
    "\t   '''<image id=\"preview\" x=\"0\" y=\"{legend_size}\" width=\"{legend_size}\" height=\"{legend_size}\" />\n",
    "\t   <text id=\"label\" x=\"0\" y=\"{legend_size}\" font-size=\"{legend_font_size}\" />\n",
    "\t   </svg>'''.format(legend_size = legend_size, legend_font_size = legend_font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_embeddings = tsne(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('train_tsne.svg', 'w').write(svg(tsne_embeddings, person_id, thumbnails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = train_embeddings.numpy()\n",
    "np.correlate(train_embeddings, gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.mutual_info_score(train_embeddings, gender, contingency=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
