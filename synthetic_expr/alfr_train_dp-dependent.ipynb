{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms, utils, models, datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer_dataloader import *\n",
    "from networks import *\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 96\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set: cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = False\n",
    "pin_memory = False\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    cuda = True\n",
    "    cudnn.benchmark = True\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Device set: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "#             transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/var/synthetic_data/dependent_gen/'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "VAL_PATH = os.path.join(DATA_PATH, 'valid')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = datasets.ImageFolder(root=TRAIN_PATH, transform=data_transforms['train'])\n",
    "val_df = datasets.ImageFolder(root=VAL_PATH, transform=data_transforms['val'])\n",
    "test_df = datasets.ImageFolder(root=TEST_PATH, transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_df, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_df, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAFTR Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_dataloader import *\n",
    "shapegender_train = ShapeGenderDataset(train_df)\n",
    "shapegender_valid = ShapeGenderDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "laftrtrain_loader = DataLoader(shapegender_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "laftrval_loader = DataLoader(shapegender_valid, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "laftr_encoder = LeNetBN()\n",
    "# laftr_encoder = LeNet()\n",
    "laftr_adversary = ClassNet()\n",
    "laftr_classifier = ClassNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "laftr_adv_criterion = AdvDemographicParityLoss()\n",
    "# laftr_adv_criterion = nn.BCELoss()\n",
    "laftr_cls_criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "laftr_opt_adv = optim.Adam(laftr_adversary.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "laftr_opt_cls = optim.Adam(laftr_classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "laftr_opt_enc = optim.Adam(laftr_encoder.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# laftr_opt_adv = optim.SGD(laftr_adversary.parameters(), lr=0.001, momentum=0.9)\n",
    "# laftr_opt_cls = optim.SGD(laftr_classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "# laftr_opt_enc = optim.SGD(laftr_encoder.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "laftr_scheduler_adv = lr_scheduler.StepLR(optimizer=laftr_opt_adv, gamma=0.99, step_size=1)\n",
    "laftr_scheduler_cls = lr_scheduler.StepLR(optimizer=laftr_opt_cls, gamma=0.99, step_size=1)\n",
    "laftr_scheduler_enc = lr_scheduler.StepLR(optimizer=laftr_opt_enc, gamma=0.99, step_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsTrain_losses = []\n",
    "clsTrain_accs = []\n",
    "# trainCombined_losses = []\n",
    "clsTrainCombined_losses = []\n",
    "advTrain_losses = []\n",
    "advTrain_accs = []\n",
    "advTrainCombined_losses = []\n",
    "\n",
    "combinedVal_losses = []\n",
    "clsVal_losses = []\n",
    "clsVal_accs = []\n",
    "advVal_losses = []\n",
    "advVal_accs = []\n",
    "\n",
    "best_acc = 0.7\n",
    "epoch_time = AverageMeter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000\n",
      "$$*$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.7034 (0.7034)\tAdv step loss:-0.7216 (-0.5964)\n",
      "Cls Acc:0.6719 (0.6307)\tAdv Acc:0.4688 (0.4093)\n",
      "*$$$$$$$$$$$$$$$$*$$$\n",
      "Classifier accuracy: 0.632\t Adversary Accuracy: 0.3428\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6780 \t Adv validation acc: 0.2280\n",
      "--------------------\n",
      "Epoch 0/1000\tTime 16.161 sec (16.161 sec)\n",
      "--------------------\n",
      "Epoch: 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([52])) that is different to the input size (torch.Size([52, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$*$$$$$$$$$*$$$*$$$$\n",
      "Batch: [40/79]\tCls step loss:0.6539 (0.6441)\tAdv step loss:-0.5462 (-0.5534)\n",
      "Cls Acc:0.7344 (0.7069)\tAdv Acc:0.4688 (0.4466)\n",
      "$$$$*$$$$*$$$$$$$$$$$\n",
      "Classifier accuracy: 0.7036\t Adversary Accuracy: 0.4826\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6640 \t Adv validation acc: 0.5740\n",
      "--------------------\n",
      "Epoch 1/1000\tTime 15.656 sec (15.909 sec)\n",
      "--------------------\n",
      "Epoch: 2/1000\n",
      "$*$$*$$$$$$$$$$$*$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.7663 (0.7085)\tAdv step loss:-0.7644 (-0.7037)\n",
      "Cls Acc:0.6406 (0.6288)\tAdv Acc:0.6562 (0.5065)\n",
      "$$*$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.647\t Adversary Accuracy: 0.51\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6720 \t Adv validation acc: 0.5400\n",
      "--------------------\n",
      "Epoch 2/1000\tTime 16.140 sec (15.986 sec)\n",
      "--------------------\n",
      "Epoch: 3/1000\n",
      "$$$$*$$$$$$$$$$*$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.9008 (0.7615)\tAdv step loss:-0.7844 (-0.6929)\n",
      "Cls Acc:0.5156 (0.6101)\tAdv Acc:0.5312 (0.5293)\n",
      "$$$$$$$*$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6388\t Adversary Accuracy: 0.513\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7620 \t Adv validation acc: 0.4800\n",
      "saving weights\n",
      "--------------------\n",
      "Epoch 3/1000\tTime 16.220 sec (16.044 sec)\n",
      "--------------------\n",
      "Epoch: 4/1000\n",
      "$$$$$$$$$$$$$$$*$*$$$$*$\n",
      "Batch: [40/79]\tCls step loss:0.7069 (0.7010)\tAdv step loss:-0.7190 (-0.6787)\n",
      "Cls Acc:0.7344 (0.7268)\tAdv Acc:0.4219 (0.5175)\n",
      "$$$*$$$$$*$$$$$$$$$*$$\n",
      "Classifier accuracy: 0.6996\t Adversary Accuracy: 0.5254\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6480 \t Adv validation acc: 0.5860\n",
      "--------------------\n",
      "Epoch 4/1000\tTime 15.927 sec (16.021 sec)\n",
      "--------------------\n",
      "Epoch: 5/1000\n",
      "$*$$$*$$$$$$$$$$$*$*$*$$$$\n",
      "Batch: [40/79]\tCls step loss:0.7431 (0.7312)\tAdv step loss:-0.6833 (-0.6222)\n",
      "Cls Acc:0.7969 (0.7363)\tAdv Acc:0.5938 (0.5400)\n",
      "$$*$*$$$*$$$*$*$$$$$$$$*$\n",
      "Classifier accuracy: 0.6738\t Adversary Accuracy: 0.5426\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.5660 \t Adv validation acc: 0.5620\n",
      "--------------------\n",
      "Epoch 5/1000\tTime 15.385 sec (15.915 sec)\n",
      "--------------------\n",
      "Epoch: 6/1000\n",
      "$$$*$$$$$$$$$$$$$$$*$$$\n",
      "Batch: [40/79]\tCls step loss:0.8301 (0.8193)\tAdv step loss:-0.7638 (-0.7754)\n",
      "Cls Acc:0.6719 (0.6391)\tAdv Acc:0.5625 (0.5339)\n",
      "$$$*$$*$$*$$$*$$$$$$$$$\n",
      "Classifier accuracy: 0.617\t Adversary Accuracy: 0.5228\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6100 \t Adv validation acc: 0.5220\n",
      "--------------------\n",
      "Epoch 6/1000\tTime 15.851 sec (15.906 sec)\n",
      "--------------------\n",
      "Epoch: 7/1000\n",
      "$$$*$$$$$$$$*$$$$$$$$*$$\n",
      "Batch: [40/79]\tCls step loss:0.6513 (0.6799)\tAdv step loss:-0.6393 (-0.6366)\n",
      "Cls Acc:0.4062 (0.5690)\tAdv Acc:0.4375 (0.4836)\n",
      "$$$$$*$$*$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.5654\t Adversary Accuracy: 0.4714\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6040 \t Adv validation acc: 0.4640\n",
      "--------------------\n",
      "Epoch 7/1000\tTime 15.969 sec (15.914 sec)\n",
      "--------------------\n",
      "Epoch: 8/1000\n",
      "$$*$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.5813 (0.5813)\tAdv step loss:-0.5756 (-0.5193)\n",
      "Cls Acc:0.5938 (0.5869)\tAdv Acc:0.3750 (0.3891)\n",
      "$$$$$$$$$$$*$$$$$$$$\n",
      "Classifier accuracy: 0.5978\t Adversary Accuracy: 0.422\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6240 \t Adv validation acc: 0.5040\n",
      "--------------------\n",
      "Epoch 8/1000\tTime 15.928 sec (15.915 sec)\n",
      "--------------------\n",
      "Epoch: 9/1000\n",
      "$$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.0000 (0.0000)\tAdv step loss:-0.4855 (-0.5675)\n",
      "Cls Acc:0.6094 (0.6098)\tAdv Acc:0.5469 (0.4699)\n",
      "$$*$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6256\t Adversary Accuracy: 0.4784\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6460 \t Adv validation acc: 0.4960\n",
      "--------------------\n",
      "Epoch 9/1000\tTime 16.238 sec (15.948 sec)\n",
      "--------------------\n",
      "Epoch: 10/1000\n",
      "$$$$$$$$*$$$$$$$$$$*$$$\n",
      "Batch: [40/79]\tCls step loss:0.6564 (0.7115)\tAdv step loss:-0.7304 (-0.6581)\n",
      "Cls Acc:0.6875 (0.6513)\tAdv Acc:0.4531 (0.4844)\n",
      "$$$$$$$$*$$$$*$$$$$$*$\n",
      "Classifier accuracy: 0.6712\t Adversary Accuracy: 0.5036\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6860 \t Adv validation acc: 0.5160\n",
      "--------------------\n",
      "Epoch 10/1000\tTime 15.965 sec (15.949 sec)\n",
      "--------------------\n",
      "Epoch: 11/1000\n",
      "$$$$*$$$*$$$*$$$$$$$$$*$$\n",
      "Batch: [40/79]\tCls step loss:0.7272 (0.7140)\tAdv step loss:-0.6289 (-0.6369)\n",
      "Cls Acc:0.6406 (0.6768)\tAdv Acc:0.4844 (0.5202)\n",
      "$$$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6848\t Adversary Accuracy: 0.519\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7020 \t Adv validation acc: 0.4800\n",
      "--------------------\n",
      "Epoch 11/1000\tTime 15.825 sec (15.939 sec)\n",
      "--------------------\n",
      "Epoch: 12/1000\n",
      "$$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.0000 (0.0000)\tAdv step loss:-0.8233 (-0.8026)\n",
      "Cls Acc:0.7344 (0.6841)\tAdv Acc:0.5156 (0.4912)\n",
      "$$$$$$$$$$$*$$$*$$$$$\n",
      "Classifier accuracy: 0.6932\t Adversary Accuracy: 0.5058\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7260 \t Adv validation acc: 0.4800\n",
      "--------------------\n",
      "Epoch 12/1000\tTime 15.656 sec (15.917 sec)\n",
      "--------------------\n",
      "Epoch: 13/1000\n",
      "$*$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.7228 (0.7228)\tAdv step loss:-0.8034 (-0.7494)\n",
      "Cls Acc:0.7500 (0.7359)\tAdv Acc:0.5312 (0.5057)\n",
      "$$$$$$$$*$$*$$$$*$$*$$$\n",
      "Classifier accuracy: 0.7232\t Adversary Accuracy: 0.5136\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7440 \t Adv validation acc: 0.6480\n",
      "--------------------\n",
      "Epoch 13/1000\tTime 16.158 sec (15.934 sec)\n",
      "--------------------\n",
      "Epoch: 14/1000\n",
      "$*$$*$$*$$$*$*$$$$*$$*$*$$*$*$$\n",
      "Batch: [40/79]\tCls step loss:0.6537 (0.7627)\tAdv step loss:-0.5367 (-0.6718)\n",
      "Cls Acc:0.6406 (0.6364)\tAdv Acc:0.5000 (0.5587)\n",
      "$$$$$$$$$$$$*$$$*$$$$\n",
      "Classifier accuracy: 0.5934\t Adversary Accuracy: 0.5154\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.5940 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 14/1000\tTime 15.907 sec (15.932 sec)\n",
      "--------------------\n",
      "Epoch: 15/1000\n",
      "$$$$$$$$$$*$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.5661 (0.5661)\tAdv step loss:-0.6010 (-0.6854)\n",
      "Cls Acc:0.7188 (0.6193)\tAdv Acc:0.5781 (0.4962)\n",
      "$$$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6362\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6920 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 15/1000\tTime 15.844 sec (15.927 sec)\n",
      "--------------------\n",
      "Epoch: 16/1000\n",
      "$$$$$$$$$$$$$*$$$$$$$*$\n",
      "Batch: [40/79]\tCls step loss:0.6499 (0.6888)\tAdv step loss:-0.6022 (-0.6628)\n",
      "Cls Acc:0.7656 (0.6704)\tAdv Acc:0.5156 (0.5038)\n",
      "*$$*$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.7044\t Adversary Accuracy: 0.4978\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7260 \t Adv validation acc: 0.5600\n",
      "--------------------\n",
      "Epoch 16/1000\tTime 16.023 sec (15.933 sec)\n",
      "--------------------\n",
      "Epoch: 17/1000\n",
      "$*$$$$*$$$*$*$*$$*$$$*$$$$$*$\n",
      "Batch: [40/79]\tCls step loss:0.6405 (0.7073)\tAdv step loss:-0.5328 (-0.6155)\n",
      "Cls Acc:0.8125 (0.5724)\tAdv Acc:0.5938 (0.5034)\n",
      "$$$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6718\t Adversary Accuracy: 0.5006\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7620 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 17/1000\tTime 16.637 sec (15.972 sec)\n",
      "--------------------\n",
      "Epoch: 18/1000\n",
      "$$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.0000 (0.0000)\tAdv step loss:-0.5964 (-0.5549)\n",
      "Cls Acc:0.7344 (0.7862)\tAdv Acc:0.6406 (0.4920)\n",
      "$$$$$$$$$$$*$*$$*$$$$$\n",
      "Classifier accuracy: 0.7646\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6560 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 18/1000\tTime 16.039 sec (15.975 sec)\n",
      "--------------------\n",
      "Epoch: 19/1000\n",
      "$$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.0000 (0.0000)\tAdv step loss:-0.6308 (-0.6049)\n",
      "Cls Acc:0.6250 (0.6639)\tAdv Acc:0.4844 (0.5042)\n",
      "$$$$$$$$$$$$$$$$*$*$$\n",
      "Classifier accuracy: 0.65\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6480 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 19/1000\tTime 15.938 sec (15.973 sec)\n",
      "--------------------\n",
      "Epoch: 20/1000\n",
      "$$$$$$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.0000 (0.0000)\tAdv step loss:-0.6244 (-0.6358)\n",
      "Cls Acc:0.5781 (0.6124)\tAdv Acc:0.4531 (0.4901)\n",
      "$$$$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.6208\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6480 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 20/1000\tTime 16.035 sec (15.976 sec)\n",
      "--------------------\n",
      "Epoch: 21/1000\n",
      "$$$$$$*$$*$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.5431 (0.5775)\tAdv step loss:-0.5031 (-0.6143)\n",
      "Cls Acc:0.7500 (0.6437)\tAdv Acc:0.6094 (0.4977)\n",
      "$$$$$$$$$$$$$$*$$*$$$\n",
      "Classifier accuracy: 0.6496\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.6960 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 21/1000\tTime 15.703 sec (15.964 sec)\n",
      "--------------------\n",
      "Epoch: 22/1000\n",
      "$$*$$$*$$$$$$$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.4515 (0.5021)\tAdv step loss:-0.4782 (-0.4726)\n",
      "Cls Acc:0.7344 (0.7828)\tAdv Acc:0.4531 (0.5076)\n",
      "$$$*$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.7862\t Adversary Accuracy: 0.4962\n",
      "----------\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "Classifier validation acc: 0.7240 \t Adv validation acc: 0.5200\n",
      "--------------------\n",
      "Epoch 22/1000\tTime 15.923 sec (15.962 sec)\n",
      "--------------------\n",
      "Epoch: 23/1000\n",
      "$$$$$$*$$$$$*$$$$$$$$$$\n",
      "Batch: [40/79]\tCls step loss:0.4076 (0.4496)\tAdv step loss:-0.3618 (-0.4285)\n",
      "Cls Acc:0.8594 (0.8007)\tAdv Acc:0.5312 (0.4935)\n",
      "$$$*$$$$$$$$$$$$$$$$\n",
      "Classifier accuracy: 0.8126\t Adversary Accuracy: 0.4962\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-190:\n",
      "Process Process-191:\n",
      "Process Process-189:\n",
      "Traceback (most recent call last):\n",
      "Process Process-192:\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/fairness/synthetic_expr/synthetic_dataloader.py\", line 41, in __getitem__\n",
      "    img, shape = self.dataset[idx]\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/fairness/synthetic_expr/synthetic_dataloader.py\", line 41, in __getitem__\n",
      "    img, shape = self.dataset[idx]\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/fairness/synthetic_expr/synthetic_dataloader.py\", line 41, in __getitem__\n",
      "    img, shape = self.dataset[idx]\n",
      "  File \"/home/var/fairness/synthetic_expr/synthetic_dataloader.py\", line 41, in __getitem__\n",
      "    img, shape = self.dataset[idx]\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 206, in resize\n",
      "    return img.resize(size[::-1], interpolation)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 206, in resize\n",
      "    return img.resize(size[::-1], interpolation)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-046a6df7f401>\", line 29, in <module>\n",
      "    laftr_cls_criterion, laftr_adv_criterion, device)\n",
      "  File \"/home/var/fairness/synthetic_expr/trainer_dataloader.py\", line 439, in laftr_validate_dp\n",
      "    for batch_idx, (imgs, shape, color) in enumerate(dataloader):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/posixpath.py\", line 421, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 1735) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ep_end = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "#         print('-'*80)\n",
    "        print('Epoch: {}/{}'.format(epoch, num_epochs))\n",
    "\n",
    "        laftr_scheduler_adv.step()\n",
    "        laftr_scheduler_cls.step()\n",
    "        laftr_scheduler_enc.step()\n",
    "        \n",
    "        cls_loss, cls_en_acc, adv_loss, adv_acc, cls_en_combinedLoss, adv_combinedLoss = alfr_train(laftrtrain_loader,\n",
    "                                                        laftr_encoder, laftr_classifier, laftr_adversary, laftr_opt_enc,\n",
    "                                                        laftr_opt_cls, laftr_opt_adv, \n",
    "                                                        laftr_cls_criterion, laftr_adv_criterion, device)\n",
    "        \n",
    "        clsTrain_losses.append(cls_loss)\n",
    "        clsTrain_accs.append(cls_en_acc)\n",
    "        clsTrainCombined_losses.append(cls_en_combinedLoss)\n",
    "        advTrain_losses.append(adv_loss)\n",
    "        advTrain_accs.append(adv_acc)\n",
    "#         trainCombined_losses.append(combined_loss)\n",
    "        advTrainCombined_losses.append(adv_combinedLoss)\n",
    "        \n",
    "        print('\\nClassifier accuracy: {}\\t Adversary Accuracy: {}'.format(cls_en_acc, adv_acc))\n",
    "        # validate\n",
    "        print('-'*10)\n",
    "        \n",
    "        combinedVal_loss, clsVal_loss, clsVal_acc, advVal_loss, advVal_acc = laftr_validate_dp(laftrval_loader,\n",
    "                                                        laftr_encoder, laftr_classifier, laftr_adversary, \n",
    "                                                        laftr_cls_criterion, laftr_adv_criterion, device)\n",
    "        \n",
    "        combinedVal_losses.append(combinedVal_loss)\n",
    "        clsVal_losses.append(clsVal_loss)\n",
    "        clsVal_accs.append(clsVal_acc)\n",
    "        advVal_losses.append(advVal_loss)\n",
    "        advVal_accs.append(advVal_acc)\n",
    "        \n",
    "        print('%'*20)\n",
    "        print('Classifier validation acc: {:.4f} \\t Adv validation acc: {:.4f}'.format(clsVal_acc, advVal_acc))\n",
    "        \n",
    "        if clsVal_acc > best_acc and advVal_acc < 0.9:\n",
    "            best_acc = clsVal_acc\n",
    "            print('saving weights')\n",
    "            torch.save(laftr_encoder, './weights/encoder_{}_{}.pth'.format(epoch, clsVal_acc))\n",
    "            torch.save(laftr_classifier, './weights/cls_{}_{}.pth'.format(epoch, clsVal_acc))\n",
    "            torch.save(laftr_adversary, './weights/adv_{}_{}.pth'.format(epoch, advVal_acc))\n",
    "\n",
    "        print('-' * 20)\n",
    "        epoch_time.update(time.time() - ep_end)\n",
    "        ep_end = time.time()\n",
    "        print('Epoch {}/{}\\t'\n",
    "              'Time {epoch_time.val:.3f} sec ({epoch_time.avg:.3f} sec)'.format(epoch, num_epochs, epoch_time=epoch_time))\n",
    "        print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(431)\n",
    "plt.title('Combined Val Loss')\n",
    "# plt.plot(trainCombined_losses, label='Train')\n",
    "plt.plot(combinedVal_losses, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(432)\n",
    "plt.title('Cls-Enc Loss')\n",
    "plt.plot(clsTrain_losses, label='Train')\n",
    "plt.plot(clsVal_losses, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(433)\n",
    "plt.title('Cls-Enc Accuracy')\n",
    "plt.plot(clsTrain_accs, label='Train')\n",
    "plt.plot(clsVal_accs, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(434)\n",
    "plt.title('Adv Loss')\n",
    "plt.plot(advTrain_losses, label='Train')\n",
    "plt.plot(advVal_losses, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(435)\n",
    "plt.title('Adv Accuracy')\n",
    "plt.plot(advTrain_accs, label='Train')\n",
    "plt.plot(advVal_accs, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(436)\n",
    "plt.title('Step Loss')\n",
    "plt.plot(advTrainCombined_losses, label='Adversary')\n",
    "plt.plot(clsTrainCombined_losses, label='Classifier')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./plots/laftr_train_{}{}.pdf'.format(time.localtime().tm_hour, time.localtime().tm_min))\n",
    "pkl_path = './plots/metrics_{}{}.pkl'.format(time.localtime().tm_hour, time.localtime().tm_min)\n",
    "with open(pkl_path, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([advTrainCombined_losses, clsTrainCombined_losses, combinedVal_losses, clsTrain_losses,\n",
    "                 clsVal_losses, clsTrain_accs, clsVal_accs, advTrain_losses, advVal_losses, advTrain_accs, advVal_accs], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_train = GenderDataset(train_df)\n",
    "gender_valid = GenderDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advtrain_loader = DataLoader(gender_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "advval_loader = DataLoader(gender_valid, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = ClassNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.BCELoss()\n",
    "# adv_criterion = AdvDemographicParityLoss()\n",
    "opt_adv = optim.Adam(adversary.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "scheduler_adv = lr_scheduler.StepLR(optimizer=opt_adv, gamma=0.99, step_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "epoch_time = AverageMeter()\n",
    "ep_end = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "        print('Epoch: {}/{}'.format(epoch, num_epochs))\n",
    "        scheduler_adv.step()\n",
    "        # train\n",
    "        train_loss, train_acc = train_classifier_epoch(advtrain_loader, laftr_encoder,\n",
    "                                adversary, opt_adv, adv_criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        # validate\n",
    "        print('-'*10)\n",
    "        val_loss, val_acc = validate_classifier_epoch(advval_loader, laftr_encoder, adversary,\n",
    "                                 adv_criterion, device)\n",
    "\n",
    "        print('Avg validation loss: {} \\t Accuracy: {}'.format(val_loss, val_acc))\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print('-' * 20)\n",
    "        epoch_time.update(time.time() - ep_end)\n",
    "        ep_end = time.time()\n",
    "        print('Epoch {}/{}\\t'\n",
    "              'Time {epoch_time.val:.3f} sec ({epoch_time.avg:.3f} sec)'.format(epoch, num_epochs, epoch_time=epoch_time))\n",
    "        print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.title('training classification loss')\n",
    "plt.plot(train_losses)\n",
    "plt.subplot(222)\n",
    "plt.title('training accuracy')\n",
    "plt.plot(train_accs)\n",
    "plt.subplot(223)\n",
    "plt.title('validation loss')\n",
    "plt.plot(val_losses)\n",
    "plt.subplot(224)\n",
    "plt.title('validation accuracy')\n",
    "plt.plot(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
